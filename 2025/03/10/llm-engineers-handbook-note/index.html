<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>llm_engineers_handbook_note | Lost N Found</title><meta name="author" content="Guohao"><meta name="copyright" content="Guohao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="《LLM Engineer’s Handbook》本书的个人学习笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="llm_engineers_handbook_note">
<meta property="og:url" content="https://lostnfound.top/2025/03/10/llm-engineers-handbook-note/index.html">
<meta property="og:site_name" content="Lost N Found">
<meta property="og:description" content="《LLM Engineer’s Handbook》本书的个人学习笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lostnfound.top/linear-gradient(45deg,%20#8EC3B0,%20#9ED5C5,%20#F8C4B4,%20#FF8787)">
<meta property="article:published_time" content="2025-03-10T05:04:09.000Z">
<meta property="article:modified_time" content="2025-03-10T09:31:12.003Z">
<meta property="article:author" content="Guohao">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="DeepLearning">
<meta property="article:tag" content="Engineering">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lostnfound.top/linear-gradient(45deg,%20#8EC3B0,%20#9ED5C5,%20#F8C4B4,%20#FF8787)"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="https://lostnfound.top/2025/03/10/llm-engineers-handbook-note/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":100,"languages":{"author":"作者: Guohao","link":"链接: ","source":"来源: Lost N Found","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'llm_engineers_handbook_note',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-03-10 17:31:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="Lost N Found" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">42</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-battery-full"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-calendar-check"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-hashtag"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-user-circle"></i><span> 关于我</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://github.com/Dave0126"><i class="fa-fw fab fa-github"></i><span> Github</span></a></li><li><a class="site-page child" href="mailto:dave980126@outlook.com"><i class="fa-fw fas fa-envelope"></i><span> Mail</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background: linear-gradient(45deg, #8EC3B0, #9ED5C5, #F8C4B4, #FF8787)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Lost N Found</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-battery-full"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-calendar-check"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-hashtag"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-user-circle"></i><span> 关于我</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://github.com/Dave0126"><i class="fa-fw fab fa-github"></i><span> Github</span></a></li><li><a class="site-page child" href="mailto:dave980126@outlook.com"><i class="fa-fw fas fa-envelope"></i><span> Mail</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">llm_engineers_handbook_note</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-10T05:04:09.000Z" title="发表于 2025-03-10 13:04:09">2025-03-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-03-10T09:31:12.003Z" title="更新于 2025-03-10 17:31:12">2025-03-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/LLM/">LLM</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.7k</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>写在前面：</p>
<p>本文章是关于《LLM Engineer’s Handbook》的部分学习笔记。碍于本人学识有限，部分叙述难免存在纰漏，请读者注意甄别。</p>
<p>参考资料：</p>
<ul>
<li>《LLM Engineer’s Handbook》书中示例代码：[<code>Github</code>]( <a target="_blank" rel="noopener" href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a> LLM-Engineers-Handbook)</li>
</ul>
<hr>
<h1 id="零-前言"><a class="markdownIt-Anchor" href="#零-前言"></a> 零、前言</h1>
<p>大型语言模型（Large Language Model, LLM）工程领域迅速崛起，已成为人工智能和机器学习中的关键领域。随着 LLM 持续革新自然语言处理和生成技术，能够在实际场景中有效实施、优化和部署这些模型的专业人士需求呈指数级增长。LLM 工程涵盖从<u><em>数据准备</em></u>、<u><em>模型微调</em></u>到<u><em>推理优化</em></u>和<u><em>生产部署</em></u>等广泛学科，要求软件工程、机器学习专业知识和领域知识的独特融合。</p>
<p>机器学习运维（Machine Learning Operations, MLOps）在成功实施 LLM 于生产环境中起着至关重要的作用。MLOps 将 DevOps 的原则扩展至机器学习项目，专注于自动化和简化整个 ML 生命周期。对于 LLM 而言，由于其模型的复杂性和规模，MLOps 尤为重要。它解决了诸如管理大型数据集、处理模型版本控制、确保可重复性以及维持模型性能等挑战。通过融入 MLOps 实践，LLM 项目可以实现更高的效率、可靠性和可扩展性，最终促成更成功和有影响力的部署。</p>
<p>《LLM Engineer’s Handbook》是一本全面指南（以下简称“手册”），旨在将最佳实践应用于 LLM 工程领域。手册中涵盖数据工程、监督微调、模型评估、推理优化和检索增强生成（Retrieval-Augmented Generation, RAG）管道开发等主题。</p>
<p>为直观展示这些概念，手册中将开发一个名为 <code>LLM Twin</code> 的端到端项目，目标是模仿某人的写作风格和个性。该用例将展示如何构建一个最小可行产品以解决特定问题，运用 LLM 工程和 MLOps 的各个方面。我们读者将了解：</p>
<ul>
<li>如何为 LLM 收集和准备数据、针对特定任务微调模型、优化推理性能以及实施RAG管道；</li>
<li>如何评估LLM性能、使模型与人类偏好对齐；</li>
<li>部署基于LLM的应用程序。</li>
</ul>
<p>本笔记与手册结构保持一致，主要分为以下几个内容：</p>
<ul>
<li><strong>第1章 理解 <code>LLM Twin</code> 的概念和架构</strong>：介绍了贯穿全手册的 <code>LLM Twin</code> 项目，作为生产级 LLM 应用的端到端示例。定义了构建可扩展机器学习系统的 FTI 架构，并将其应用于 <code>LLM Twin</code> 的用例；</li>
<li><strong>第2章 工具和安装</strong>：介绍用于构建实际 LLM 应用的 Python、MLOps 和云工具，如编排器、实验跟踪器、提示监控和 LLM 评估工具。展示了如何在本地安装和使用这些工具以进行测试和开发；</li>
<li><strong>第3章 数据工程</strong>：介绍一个数据收集管道的实现，该管道从 <a target="_blank" rel="noopener" href="https://medium.com">Medium</a>、<a target="_blank" rel="noopener" href="https://github.com">GitHub</a> 和 <a target="_blank" rel="noopener" href="https://substack.com/home-i">Substack</a> 等多个网站抓取数据，并将原始数据存储在数据仓库中。强调了在实际机器学习应用中，从动态来源收集原始数据的重要性，而非依赖静态数据集；</li>
<li><strong>第4章 RAG 特征管道</strong>：介绍了检索增强生成（Retrieval-Augmented Generation, RAG）的基本概念，如 Embeddings、基础 RAG 框架、向量数据库，以及如何优化 RAG 应用。通过使用软件最佳实践，设计并实现了 LLM Twin 的 RAG 特征管道，以应用 RAG 理论；</li>
<li><strong>第5章 监督微调（Supervised Fine-Tuning, SFT）</strong>：探讨了使用<u>***指令（instruction）-回答（answer）***</u>对来优化预训练语言模型以执行特定任务的过程。涵盖了创建高质量数据集、实施全量微调（full fine-tuning）、LoRA 和 QLoRA 等微调技术，并提供了在自定义数据集上微调 <a href><code>Llama 3.1 8B</code></a> 模型的实践示范；</li>
<li><strong>第6章 带偏好对齐的微调</strong>：介绍了将语言模型与人类偏好对齐的技术，重点关注直接偏好优化（Direct Preference Optimization, DPO）。涵盖了创建自定义偏好数据集、实施 DPO，并提供了使用 <code>Unsloth</code> 库对 <code>TwinLlama-3.1-8B</code> 模型进行对齐的实践示范；</li>
<li><strong>第7章 评估LLM</strong>：详细描述了评估语言模型和 LLM 系统性能的各种方法。介绍通用和特定领域的评估，讨论流行的基准测试。本章包括对 <code>TwinLlama-3.1-8B</code> 模型的多标准实践评估；</li>
<li><strong>第8章 推理优化</strong>：涵盖了关键的优化策略，如推测解码、模型并行和权重量化。将讨论如何提高推理速度、降低延迟和最小化内存使用，介绍流行的推理引擎并比较其特性；</li>
<li><strong>第9章 RAG推理管道</strong>：通过从头开始实施自查询、重排序和过滤向量搜索等方法，探索高级 RAG 技术。涵盖了设计和实现 <code>LLM Twin</code> 的 RAG 推理管道，以及类似于 <code>LangChain</code> 等流行框架的自定义检索模块；</li>
<li><strong>第10章 推理管道部署</strong>：介绍了在线、异步和批量推理等机器学习部署策略，有助于将微调后的 <code>LLM Twin</code> 模型架构并部署到AWS SageMaker，并构建 FastAPI 微服务，将 RAG 推理管道作为 RESTful API 公开；</li>
<li><strong>第11章 MLOps和LLMOps</strong>：介绍了 LLMOps 的概念，从其在 DevOps 和 MLOps 中的根源开始。本章解释了如何将 <code>LLM Twin</code> 项目部署到云端，如将机器学习管道部署到 AWS，并展示了如何使用 Docker 容器化代码和构建 CI/CD/CT 管道。还在 <code>LLM Twin</code> 的推理管道上添加了提示监控层；</li>
<li><strong>附录 MLOps原则</strong>：涵盖了用于构建可扩展、可重复和健壮的机器学习应用的六项 MLOps 原则。</li>
</ul>
<h1 id="一-理解-llm-twin-的概念和架构"><a class="markdownIt-Anchor" href="#一-理解-llm-twin-的概念和架构"></a> 一、理解 <code>LLM Twin</code> 的概念和架构</h1>
<p>手册将教我们如何构建一个 <code>LLM Twin</code>，即一个通过将特定个人的写作风格、语气和个性融入 LLM 的 AI 角色。通过这个示例，我们将经历完整的 ML 生命周期，从数据收集到部署和监控。在实现 <code>LLM Twin</code> 的过程中学到的大多数概念都可以应用于其他基于 LLM 或 ML 的应用程序。</p>
<blockquote>
<p>The best way to learn about LLMs and production machine learning (ML) is to get your hands dirty and build systems.</p>
<p>学习LLM和生产级机器学习（ML）的最佳方式是亲自动手构建系统。</p>
</blockquote>
<p>在开始实施新产品时，从工程的角度来看，我们必须在开始构建之前经过三个规划步骤：</p>
<ul>
<li>首先，了解我们试图解决的问题以及我们想要构建的内容至关重要。在我们的案例中，<code>LLM Twin</code> 究竟是什么？为什么要构建它？这一步是我们必须思考并专注于<u>***“WHY”***</u>的地方。</li>
<li>其次，为了反映现实世界的场景，我们将设计一个具有最小功能的产品的初级版本。在这里，我们必须清楚地定义产品所具有的核心功能。这些选择是基于时间表、资源和团队知识做出的。这是我们在构思阶段和实际实施之间架起桥梁，并最终回答以下问题：“我们要构建什么（<u><em><strong>WHAT</strong></em></u>）？”。</li>
<li>最后，我们将进行系统设计步骤，列出用于构建 LLM 系统的核心架构和设计选型。前两个步主要与产品的设计相关，而最后一个是技术性的，专注于<u>***“HOW”***</u>。</li>
</ul>
<p>这三个步骤是在构建现实世界产品时自然发生的。虽然前两个不需要太多的 ML 知识，但是这对于产品的开发而言同样至关重要。简而言之，本章涵盖以下主题：</p>
<ul>
<li>理解 <code>LLM Twin</code> 概念</li>
<li>规划 <code>LLM Twin</code> 产品的最小可行产品（Minimum Viable Product, MVP）</li>
<li>使用特征/训练/推理管道构建 ML 系统</li>
<li>设计 <code>LLM Twin</code> 的系统架构</li>
</ul>
<h2 id="什么是-llm-twin"><a class="markdownIt-Anchor" href="#什么是-llm-twin"></a> 什么是 <code>LLM Twin</code></h2>
<p><code>LLM Twin</code> 是一个将个性化的写作风格、语气融入大型语言模型（LLM）中的 AI 角色。与在整个互联网数据上训练的通用 LLM 不同，<code>LLM Twin</code> 是在个人数据上进行微调的，将这些个人数据“<em>投射（projected）</em>”到大语言模型中。</p>
<blockquote>
<p>[!NOTE]</p>
<p>这里有意使用了“<em>投射（projected）</em>”一词。正如其他投射一样，在此过程中丢失大量信息，<u><em><strong>大模型只能反映出训练数据中信息</strong></em></u>。</p>
</blockquote>
<p>如果我们用鲁迅的文学作品微调 LLM，LLM 将会模仿鲁迅的写作风格，这也被称为风格迁移。我们将利用风格迁移策略，使 LLM 模仿我们个人的风格。</p>
<p>为了将 LLM 调整为特定的风格和语气，除了微调外，我们还将利用各种高级的检索增强生成（RAG）技术，以使用我们先前的 Embedding 来调节自回归过程。我们将在后续章节中详细探讨这些内容。</p>
<blockquote>
<p>[!TIP]</p>
<p><strong>什么是向量 Embedding ？</strong></p>
<p>在 LLM 的开发领域中，向量 Embedding 在获取文本信息的本质方面起着关键作用。向量 Embedding 的核心是指在数学空间中将单词、句子甚至整个文档表示为密集的低维向量的过程。与依赖于稀疏表示（如one-hot编码）的传统方法不同，向量 Embeddings封装了单词之间的语义关系，并使算法能够理解它们的上下文含义。</p>
<p>通过使用词 Embeddings、句子 Embeddings 或上下文 Embedding 等技术，向量 Embeddings 提供了文本数据的紧凑而有意义的表示。例如，单词 Embeddings 将单词映射到固定长度的向量，其中具有相似含义的单词在向量空间中的位置更接近。这允许高效的语义搜索、信息检索和语言理解任务。</p>
<p>向量 Embedding 的重要性在于它能够将原始文本转换为算法可以理解和推理的数字表示。这种转换过程不仅促进了各种自然语言处理（NLP）任务，而且还作为大型语言模型的基本构建块。向量 Embeddings 使这些模型能够利用嵌入在文本数据中的丰富语义信息，使它们能够生成更连贯和上下文更合适的响应。</p>
</blockquote>
<p>我们可以想象这样一个可以对 LLM 进行微调的场景：</p>
<ul>
<li>小红书、知乎等社交平台：使 LLM 仿照我们自己的风格来编写社交媒体内容；</li>
<li>学术论文和文章：微调 LLM 以撰写正式和学术性的内容；</li>
<li>代码：微调 LLM 使其以特定的代码规范来编写代码。</li>
</ul>
<p>所有上述场景都可以归结为一个核心策略：收集个人数据集（或其中的一部分），使用不同的算法将其输入到 LLM 中。最终，LLM 将反映所收集数据的语气和风格。</p>
<h3 id="为什么不用-qwen-这些通用大模型"><a class="markdownIt-Anchor" href="#为什么不用-qwen-这些通用大模型"></a> 为什么不用 <code>Qwen</code> 这些通用大模型？</h3>
<p><code>Qwen</code> 这些通用大模型非常通用、缺乏独特表达，且往往冗长。盲目使用通用大模型可能会导致以下问题：</p>
<ul>
<li><strong>幻觉导致的错误信息</strong>：需要手动检查生成内容是否存在幻觉，或使用第三方工具进行验证，是一项繁琐且低效的任务。</li>
<li><strong>繁琐的手动提示工程</strong>：需要手动编写提示词并注入外部信息，这个过程既耗时又麻烦。此外，由于无法完全控制提示词和输入数据，在不同会话中生成一致的答案也十分困难。虽然可以通过 API 和 <code>LangChain</code> 等工具部分解决此问题，但这需要一定的编程经验。</li>
</ul>
<p>如果想要高质量且真正有价值的内容时，我们可能会花比直接写作更多的时间去调试 AI 生成的文本。</p>
<p>由此可见，构建私人的大语言模型的关键点在于：</p>
<ul>
<li>我们收集哪些数据</li>
<li>如何预处理这些数据</li>
<li>如何将数据输入 LLM</li>
<li>如何链接多个提示以获得理想结果</li>
<li>如何评估生成的内容</li>
</ul>
<h3 id="规划产品的-mvp"><a class="markdownIt-Anchor" href="#规划产品的-mvp"></a> 规划产品的 MVP</h3>
<p>既然我们已经了解了什么是 LLM Twin 以及为什么要构建它，那么我们需要明确定义产品的功能。手册中重点关注 <code>LLM Twin</code> 的第一版，即<strong>最小可行产品（Minimum Viable Product, MVP）</strong>，以遵循大多数产品的自然发展周期。</p>
<h4 id="什么是-mvp"><a class="markdownIt-Anchor" href="#什么是-mvp"></a> 什么是 MVP?</h4>
<p>MVP 指的是产品的<strong>最小可行版本</strong>，即仅包含足够功能来吸引早期用户，并在开发的初始阶段验证产品概念的可行性。通常，MVP 的目标是以最小的投入<strong>从市场中收集反馈</strong>。</p>
<p>MVP 是一种产品策略，主要有以下优势：</p>
<ul>
<li><strong>加速产品上市（Accelerated time-to-market）</strong>：快速推出产品，以获得早期用户并建立市场影响力。</li>
<li><strong>验证产品理念（Idea validation）</strong>：在全面开发产品之前，通过真实用户进行测试，以验证产品是否符合需求。</li>
<li><strong>市场调研（Market research）</strong>：深入了解目标用户的偏好，收集有价值的市场反馈。</li>
<li><strong>降低风险（Risk minimization）</strong>：减少因产品市场表现不佳而浪费的时间和资源。</li>
</ul>
<p>在 MVP 中，必须严格<u>***遵循 “V”（Viable，可行性）***</u> 的原则，即产品必须是可行的。即使产品功能最小化，它也必须提供<u><em><strong>完整的用户体验</strong></em></u>，而不是半成品。MVP 需要是一个真正可用的产品，提供流畅的使用体验，让用户愿意持续使用，并随着产品的发展而发展。</p>
<h4 id="llm-twin-的-mvp-的核心功能"><a class="markdownIt-Anchor" href="#llm-twin-的-mvp-的核心功能"></a> <code>LLM Twin</code> 的 MVP 的核心功能</h4>
<p>为了保持简单性，我们的 LLM Twin MVP 将具备以下核心功能：</p>
<ol>
<li><strong>数据收集</strong>
<ul>
<li>从 <strong>小红书、知乎、微信 和 GitHub</strong> 账户收集用户的数据。</li>
</ul>
</li>
<li><strong>LLM 训练微调</strong>
<ul>
<li>使用<strong>开源 LLM</strong>，结合收集的数据进行微调（fine-tuning）。</li>
</ul>
</li>
<li><strong>RAG（检索增强生成）</strong>
<ul>
<li>将收集的数字数据存入<strong>向量数据库（vector database）</strong>，以支持 RAG 机制。</li>
</ul>
</li>
<li><strong>社交媒体内容生成</strong>（例如小红书文章）
<ul>
<li><strong>用户输入的提示（prompts）</strong></li>
<li><strong>RAG 检索</strong>，复用并引用用户过往内容</li>
<li><strong>新内容</strong>（如文章、论文等）作为 LLM 额外的知识输入</li>
</ul>
</li>
<li><strong>简单的 Web 界面</strong>，提供交互能力：
<ul>
<li><strong>配置社交媒体链接</strong>，并触发数据收集流程</li>
<li><strong>输入提示词（prompts）或外部资源链接</strong>，让 LLM Twin 生成内容</li>
</ul>
</li>
</ol>
<h4 id="mvp-的关键挑战"><a class="markdownIt-Anchor" href="#mvp-的关键挑战"></a> MVP 的关键挑战</h4>
<p>尽管上述 MVP 可能看起来功能不多，但我们必须确保<strong>系统具备以下特性</strong>：</p>
<ul>
<li><strong>成本可控</strong>（Cost-effective）：优化计算资源，避免不必要的开销。</li>
<li><strong>可扩展</strong>（Scalable）：随着用户增长，系统仍能稳定运行。</li>
<li><strong>模块化</strong>（Modular）：方便未来扩展和优化。</li>
</ul>
<p>至此，我们已经从<strong>用户和商业角度</strong>探讨了<code>LLM Twin</code> 的价值。<strong>最后一步</strong>，我们需要<strong>从工程实现的角度</strong>进行分析，并制定开发计划，明确<strong>如何在技术层面实现这个系统</strong>。</p>
<blockquote>
<p>[!NOTE]</p>
<p>从现在开始，重点将<strong>转向 <code>LLM Twin</code> 的具体实现</strong>。即使我们专注于上述<strong>核心功能</strong>，我们仍会基于<strong>最新的 LLM 研究成果</strong>，并结合<strong>最佳的软件工程与 MLOps 实践</strong>，构建<strong>一个成本可控、可扩展的 LLM 应用</strong>。</p>
</blockquote>
<h2 id="构建具有特征训练推理流水线的-ml-系统"><a class="markdownIt-Anchor" href="#构建具有特征训练推理流水线的-ml-系统"></a> 构建具有<code>特征/训练/推理流水线</code>的 ML 系统</h2>
<p>在深入探讨 <code>LLM Twin</code> 架构的具体细节之前，我们需要先理解其核心 ML 体系结构模式——<u><em><strong>特征/训练/推理（Feature/Training/Inference , FTI）架构</strong></em></u>。本节将概述 <u><em><strong>FTI 流水线</strong></em></u> 的设计，以及它如何帮助我们构建一个结构化的 ML 应用。</p>
<h3 id="ml-系统开发的挑战"><a class="markdownIt-Anchor" href="#ml-系统开发的挑战"></a> ML 系统开发的挑战</h3>
<p>构建生产级 ML 系统不仅仅是训练一个模型。从工程角度来看，训练模型通常是最简单的一步。然而，决定正确的架构和超参数，才是让模型真正发挥作用的挑战——这更像是一个研究问题，而不是纯粹的工程问题。</p>
<p>当前，我们关注的重点是<strong>如何设计一个可用于生产的架构</strong>。<strong>即使训练出了高准确率的模型，仅仅基于静态数据集训练它，距离真正的部署仍然很遥远。</strong> 我们需要考虑以下问题：</p>
<ul>
<li><strong>数据处理</strong>：如何**摄取（ingest）、清理（clean）和验证（validate）**新的数据？</li>
<li><strong>训练 vs 推理环境</strong>：训练和推理（Inference）环境是否需要<strong>分开部署</strong>？<strong>计算资源</strong> 如何分配？</li>
<li><strong>特征存储与计算</strong>：如何在<strong>正确的环境</strong>下<strong>计算并提供</strong>模型所需的特征？</li>
<li><strong>模型部署与服务</strong>：如何<strong>高效、低成本</strong>地提供推理服务？如何<strong>版本化、追踪并共享</strong>数据集和模型？</li>
<li><strong>监控与维护</strong>：如何<strong>监控</strong> ML 基础设施和模型的表现？<strong>模型如何扩展并持续更新</strong>？</li>
<li><strong>自动化</strong>：如何<strong>自动化</strong>模型的部署和训练流程？</li>
</ul>
<blockquote>
<p>[!TIP]</p>
<p>这些问题通常由 <strong>ML 或 MLOps 工程师</strong> 负责解决，而 <strong>研究团队或数据科学团队</strong> 主要关注<strong>模型训练</strong>本身。</p>
</blockquote>
<p>Google Cloud 团队提出的 <strong>成熟 ML &amp; MLOps 系统</strong> 需要包括的组件如下：</p>
<p><img src="/2025/03/10/llm-engineers-handbook-note/screenshot_2025-03-10_15.43.53.png" alt="screenshot_2025-03-10_15.43.53"></p>
<ul>
<li><strong>ML 代码</strong>（核心模型开发）</li>
<li><strong>数据收集</strong>（Data Collection）</li>
<li><strong>数据验证</strong>（Data Verification）</li>
<li><strong>测试与调试</strong>（Testing &amp; Debugging）</li>
<li><strong>资源管理</strong>（Resource Management）</li>
<li><strong>模型分析</strong>（Model Analysis）</li>
<li><strong>流程 &amp; 元数据管理</strong>（Process &amp; Metadata Management）</li>
<li><strong>服务基础设施</strong>（Serving Infrastructure）</li>
<li><strong>监控系统</strong>（Monitoring）</li>
</ul>
<p>可见，<strong>生产化 ML 模型远远不只是写好训练代码这么简单</strong>，它涉及多个环节和工程实践。</p>
<h3 id="如何构建一个统一的-ml-系统"><a class="markdownIt-Anchor" href="#如何构建一个统一的-ml-系统"></a> 如何构建一个统一的 ML 系统？</h3>
<p><strong>关键问题</strong>：如何将所有这些组件连接成<strong>一个统一的 ML 系统</strong>？我们需要设计一个标准化的架构，使 ML 系统的搭建更加高效、可复用和可扩展。</p>
<p>在传统软件工程中，很多应用可以拆分为 <strong>数据库（DB）、业务逻辑（Business Logic）和用户界面（UI）</strong> 三大部分。尽管每个部分的实现可能<strong>非常复杂</strong>，但在<strong>高层次的架构设计</strong>上，它们仍然可以归纳为这三大模块。</p>
<p>那么，ML 应用是否也能有类似的通用架构呢？</p>
<p>我们需要先回顾一些现有方案，看看它们为什么<strong>不适合构建可扩展的 ML 系统</strong>，然后再探索更优的解决方案。</p>
<h4 id="以往解决方案的问题"><a class="markdownIt-Anchor" href="#以往解决方案的问题"></a> 以往解决方案的问题</h4>
<p><img src="/2025/03/10/llm-engineers-handbook-note/screenshot_2025-03-10_15.47.41.png" alt="screenshot_2025-03-10_15.47.41"></p>
<p>在上图中，我们可以看到大多数 ML 应用程序中常见的架构。这种架构基于<strong>单体批处理（monolithic batch）<strong>模式，将</strong>特征创建（Create Features）</strong>、**模型训练（Train Model）<strong>和</strong>推理（Make Predictions）**紧密耦合在同一个组件中。</p>
<p>采用这种方法可以快速解决 ML 领域中的一个关键问题——<strong>训练-推理偏差（training-serving skew）</strong>。</p>
<ul>
<li><strong>训练-推理偏差</strong> 发生在<strong>训练时和推理时使用的特征计算方式不同</strong>，导致模型在生产环境中的表现不如预期。</li>
<li>在这种单体架构中，训练和推理阶段的特征是用<strong>相同的代码</strong>生成的，因此<strong>避免了训练-推理偏差</strong>。</li>
</ul>
<p><strong>单体批处理架构适用于小数据集</strong>，因为：</p>
<ul>
<li>训练、推理使用相同的特征计算代码，避免了训练-推理偏差</li>
<li>通过**批处理（batch mode）**定期运行流水线</li>
<li>预测结果通常被**第三方应用（如 dashboard）**消费</li>
</ul>
<p>然而，<strong>这种架构在面对更大规模的数据时，会引发许多问题</strong>：</p>
<ul>
<li><strong>特征无法复用</strong>（既不能在系统内部复用，也不能被其他系统使用）</li>
<li><strong>扩展性差</strong>，如果数据规模增加，必须重构代码以支持 <strong>PySpark</strong> 或 <strong>Ray</strong></li>
<li><strong>性能优化困难</strong>，如果想用 <strong>C++、Java 或 Rust</strong> 重写推理模块，会变得极为复杂</li>
<li><strong>团队协作受限</strong>，由于<strong>特征计算、训练和推理紧耦合在一起</strong>，难以拆分给不同的团队</li>
<li><strong>不支持流式计算</strong>，如果需要<strong>实时训练</strong>，无法切换到流式架构</li>
</ul>
<h5 id="单体架构在实时推理系统中的问题"><a class="markdownIt-Anchor" href="#单体架构在实时推理系统中的问题"></a> 单体架构在实时推理系统中的问题</h5>
<p><img src="/2025/03/10/llm-engineers-handbook-note/screenshot_2025-03-10_15.57.35.png" alt="screenshot_2025-03-10_15.57.35"></p>
<p>在上图中，我们可以看到类似的架构被应用于<strong>实时推理系统</strong>时会带来的额外问题。</p>
<p>在实时推理中，<u><em><strong>为了生成预测，我们必须通过客户端请求传输整个状态</strong></em></u>，以便计算特征并输入模型。例如，在电影推荐系统中，理想情况下，我们<strong>只需传递 userID</strong> 给模型，模型可以基于存储的用户数据计算推荐结果。但在单体架构中，我们必须传递<strong>整个用户状态</strong>，包括姓名、年龄、性别、观影历史等，使得客户端必须理解如何访问这些状态数据。</p>
<p><strong>这种方法极易出错</strong>，因为：</p>
<ul>
<li><strong>客户端和模型服务</strong> 强耦合，客户端必须知道如何查询和构造数据</li>
<li><strong>状态传输成本高</strong>，尤其在高并发情况下，传输大量状态信息会影响性能</li>
</ul>
<p>另一个例子是 <strong>LLM + RAG（检索增强生成）</strong> 的实现：</p>
<ul>
<li>在 <strong>RAG 模型</strong> 中，我们希望能基于<strong>外部知识库</strong>增强 LLM 的推理能力。</li>
<li>如果<strong>没有向量数据库（vector DB）</strong>，我们必须在每次查询时<strong>手动附带所有文档</strong>，否则模型无法参考这些外部知识。</li>
<li>这样就导致客户端需要<strong>手动查询和管理文档</strong>，这不仅<strong>不现实</strong>，而且是<strong>一种反模式（antipattern）</strong>。</li>
</ul>
<p>客户端不应负责查询和计算特征，而应交由服务端处理。</p>
<blockquote>
<p>我们将在<strong>第 8 章和第 9 章</strong>详细介绍 <strong>RAG</strong> 这一技术。</p>
</blockquote>
<p>综上所述，我们的<u><em><strong>核心问题是如何在不依赖客户端传递完整特征的情况下进行预测</strong></em></u>。</p>
<p>在<strong>另一端的极端案例</strong>，Google Cloud提供了一种**生产就绪（production-ready）**的、自动化流水线的 <a target="_blank" rel="noopener" href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning?hl=zh-cn">ML 架构</a>（见下图）。</p>
<p><img src="/2025/03/10/llm-engineers-handbook-note/screenshot_2025-03-10_16.10.48.png" alt="screenshot_2025-03-10_16.10.48"></p>
<p>这种架构确实<strong>能够解决生产环境中的 ML 部署问题</strong>，但它存在以下挑战：</p>
<ul>
<li><strong>复杂度高</strong>，不够直观，非 ML 生产专家很难理解</li>
<li><strong>上手难度大</strong>，如果你没有丰富的 ML 生产部署经验，可能会被架构的复杂性劝退</li>
<li><strong>不易渐进式扩展</strong>，难以理解如何从<strong>小型系统</strong>开始并随着需求增长逐步扩展</li>
</ul>
<p>在接下来的章节，我们将介绍 <strong>特征/训练/推理（Feature/Training/Inference , FTI）架构</strong>，它是一种直观的 ML 设计，能够有效<strong>解决前述的核心问题</strong>。</p>
<h3 id="特征训练推理fti-架构"><a class="markdownIt-Anchor" href="#特征训练推理fti-架构"></a> 特征/训练/推理（FTI） 架构</h3>
<blockquote>
<p>[!TIP]</p>
<p>想了解更多关于 FTI 模式的信息，可以参考*“From MLOps to ML Systems with Feature/Training/Inference Pipelines”* by Jim Dowling, CEO and co-founder of Hopsworks：<a target="_blank" rel="noopener" href="https://www.hopsworks.ai/post/mlops-to-ml-systems-with-fti-pipelines">https://www.hopsworks.ai/post/mlops-to-ml-systems-with-fti-pipelines</a></p>
</blockquote>
<p><strong>特征/训练/推理（Feature/Training/Inference , FTI）架构</strong>提出了一个清晰直接的思维框架，任何团队或个人都可以遵循它，来完成特征计算、模型训练以及推理管道的部署。该模式表明，任何机器学习系统都可以归结为三个管道：</p>
<ul>
<li>计算特征*（Feature）*</li>
<li>训练模型*（Training）*</li>
<li>进行推理*（Inference）*</li>
</ul>
<p>这种架构强大之处在于，我们可以清晰地定义每个管道的职责和接口。最终，系统只有三个核心模块，而不是像 Google Cloud 方案中展示的那种拥有二十个模块的复杂结构，这大大简化了操作和定义的难度。下图展示了特征、训练和推理管道架构。</p>
<p><img src="/2025/03/10/llm-engineers-handbook-note/screenshot_2025-03-10_16.11.00.png" alt="screenshot_2025-03-10_16.11.00"></p>
<p><strong>FTI 架构的核心特点</strong>：</p>
<ul>
<li><strong>每个管道都是独立的组件</strong>，可以<strong>在不同进程或硬件上运行</strong>。</li>
<li><strong>每个管道可以使用不同的技术实现</strong>，甚至可以由<strong>不同的团队开发和维护</strong>。</li>
<li><strong>可扩展性强</strong>，允许团队根据实际需求对不同管道<strong>独立扩展</strong>。</li>
<li><strong>提供清晰的思维导图</strong>，帮助团队<strong>高效组织 ML 系统架构</strong>。</li>
</ul>
<h4 id="特征管道feature-pipeline"><a class="markdownIt-Anchor" href="#特征管道feature-pipeline"></a> 特征管道（Feature Pipeline）</h4>
<p><strong>作用</strong>：<br>
特征管道的主要任务是<strong>从原始数据中提取特征</strong>，并生成用于<strong>模型训练或推理的特征和标签</strong>。但这些特征不会直接传递给模型，而是**存储在特征库（Feature Store）**中。</p>
<p><strong>主要职责</strong>：</p>
<ul>
<li><strong>存储、版本管理、追踪、共享</strong> 训练和推理所需的特征。</li>
<li><strong>保持特征的状态</strong>，确保训练和推理阶段使用的特征一致，从而<strong>避免训练-推理偏差（Training-Serving Skew）</strong>。</li>
<li><strong>让训练和推理管道轻松获取数据</strong>，保证系统的<strong>稳定性和可复现性</strong>。</li>
</ul>
<h4 id="训练管道training-pipeline"><a class="markdownIt-Anchor" href="#训练管道training-pipeline"></a> 训练管道（Training Pipeline）</h4>
<p><strong>作用</strong>：<br>
训练管道的任务是**从特征库中提取特征和标签，训练模型，并将训练好的模型存储在模型仓库（Model Registry）**中。</p>
<p><strong>主要职责</strong>：</p>
<ul>
<li>
<p>训练一个或多个模型，并<strong>存储、版本管理、追踪和共享</strong> 这些模型。</p>
</li>
<li>
<p><strong>模型仓库（Model Registry）</strong> 的角色类似于<strong>特征库</strong>，但重点是管理模型，而不是特征。</p>
</li>
<li>
<p>记录元数据（Metadata Store）</p>
<p>，包括：</p>
<ul>
<li>训练使用的<strong>特征、标签及其版本</strong>，确保模型的可追溯性。</li>
<li>确保团队可以随时知道<strong>模型的训练数据</strong>，方便调试和迭代。</li>
</ul>
</li>
</ul>
<h4 id="推理管道inference-pipeline"><a class="markdownIt-Anchor" href="#推理管道inference-pipeline"></a> 推理管道（Inference Pipeline）</h4>
<p><strong>作用</strong>：<br>
推理管道的任务是<strong>使用特征库中的特征数据和模型仓库中的训练模型进行推理</strong>，并生成最终的预测结果。</p>
<p><strong>主要职责</strong>：</p>
<ul>
<li>支持批量（Batch）或实时（Real-time）推理：
<ul>
<li><strong>批量模式</strong>：预测结果存入数据库（DB）。</li>
<li><strong>实时模式</strong>：预测结果直接返回给客户端。</li>
</ul>
</li>
<li><strong>版本管理</strong>：特征、标签、模型的版本都是可追踪的，这意味着可以<strong>灵活地升级或回滚模型部署</strong>。</li>
<li>动态调整模型与特征的连接关系：
<ul>
<li>例如，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">模</mi><mi mathvariant="normal">型</mi><msub><mi>M</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">模型M_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord cjk_fallback">模</span><span class="mord cjk_fallback">型</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 可能使用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><msub><mi>f</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">特征f_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><msub><mi>f</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">特征f_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><msub><mi>f</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">特征f_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，而 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">模</mi><mi mathvariant="normal">型</mi><msub><mi>M</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">模型M_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord cjk_fallback">模</span><span class="mord cjk_fallback">型</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 可能使用 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><msub><mi>f</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">特征f_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><msub><mi>f</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">特征f_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><msub><mi>f</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">特征f_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
<li>通过版本管理，我们可以<strong>快速切换或调整特征与模型的映射关系</strong>。</li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://lostnfound.top">Guohao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://lostnfound.top/2025/03/10/llm-engineers-handbook-note/">https://lostnfound.top/2025/03/10/llm-engineers-handbook-note/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://lostnfound.top" target="_blank">Lost N Found</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a><a class="post-meta__tags" href="/tags/DeepLearning/">DeepLearning</a><a class="post-meta__tags" href="/tags/Engineering/">Engineering</a></div><div class="post_share"><div class="social-share" data-image="/linear-gradient(45deg,%20#8EC3B0,%20#9ED5C5,%20#F8C4B4,%20#FF8787)" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Guohao</div><div class="author-info__description">L’existence précède l‘essence</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">42</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Dave0126" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:dave980126@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9B%B6-%E5%89%8D%E8%A8%80"><span class="toc-text"> 零、前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80-%E7%90%86%E8%A7%A3-llm-twin-%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9E%B6%E6%9E%84"><span class="toc-text"> 一、理解 LLM Twin 的概念和架构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-llm-twin"><span class="toc-text"> 什么是 LLM Twin</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E7%94%A8-qwen-%E8%BF%99%E4%BA%9B%E9%80%9A%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="toc-text"> 为什么不用 Qwen 这些通用大模型？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%84%E5%88%92%E4%BA%A7%E5%93%81%E7%9A%84-mvp"><span class="toc-text"> 规划产品的 MVP</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-mvp"><span class="toc-text"> 什么是 MVP?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#llm-twin-%E7%9A%84-mvp-%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD"><span class="toc-text"> LLM Twin 的 MVP 的核心功能</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#mvp-%E7%9A%84%E5%85%B3%E9%94%AE%E6%8C%91%E6%88%98"><span class="toc-text"> MVP 的关键挑战</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E5%85%B7%E6%9C%89%E7%89%B9%E5%BE%81%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%9A%84-ml-%E7%B3%BB%E7%BB%9F"><span class="toc-text"> 构建具有特征&#x2F;训练&#x2F;推理流水线的 ML 系统</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ml-%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91%E7%9A%84%E6%8C%91%E6%88%98"><span class="toc-text"> ML 系统开发的挑战</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%BB%9F%E4%B8%80%E7%9A%84-ml-%E7%B3%BB%E7%BB%9F"><span class="toc-text"> 如何构建一个统一的 ML 系统？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A5%E5%BE%80%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text"> 以往解决方案的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84%E5%9C%A8%E5%AE%9E%E6%97%B6%E6%8E%A8%E7%90%86%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text"> 单体架构在实时推理系统中的问题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86fti-%E6%9E%B6%E6%9E%84"><span class="toc-text"> 特征&#x2F;训练&#x2F;推理（FTI） 架构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E7%AE%A1%E9%81%93feature-pipeline"><span class="toc-text"> 特征管道（Feature Pipeline）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%AE%A1%E9%81%93training-pipeline"><span class="toc-text"> 训练管道（Training Pipeline）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A8%E7%90%86%E7%AE%A1%E9%81%93inference-pipeline"><span class="toc-text"> 推理管道（Inference Pipeline）</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background: #8EC3B0"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2025 By Guohao</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'ea138c6f176d57705144',
      clientSecret: 'c999d74b366c68c80bc3b704c716a8ff8d67af6d',
      repo: 'Dave0126.github.io',
      owner: 'Dave0126',
      admin: ['Dave0126'],
      id: '07a89b9dbc2537b90e6f494d6bb4dcbf',
      updateCountCallback: commentCount
    },))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div></div></body></html>